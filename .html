<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <title>实时频谱整形演示</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <style>
        body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif; background-color: #f0f2f5; color: #333; display: flex; flex-direction: column; align-items: center; margin: 0; padding: 20px; }
        .container { background: white; padding: 25px; border-radius: 8px; box-shadow: 0 4px 12px rgba(0,0,0,0.1); width: 90%; max-width: 800px; text-align: center; }
        h1 { color: #1a1a1a; margin-bottom: 10px; }
        p { color: #555; line-height: 1.6; }
        #toggleButton { font-size: 1.2em; padding: 12px 25px; border-radius: 5px; border: none; background-color: #007bff; color: white; cursor: pointer; transition: background-color 0.3s; margin: 20px 0; }
        #toggleButton:hover { background-color: #0056b3; }
        #toggleButton.active { background-color: #dc3545; }
        #toggleButton.active:hover { background-color: #a71d2a; }
        #visualizer { width: 100%; height: 300px; background-color: #282c34; border-radius: 5px; margin-top: 20px; }
        .warning { color: #c0392b; font-weight: bold; margin-top: 15px; }
    </style>
    <!-- 引入 fft.js 库 -->
    <script src="https://cdn.jsdelivr.net/npm/fft.js/lib/fft.js"></script>
</head>
<body>
    <div class="container">
        <h1>实时频谱整形演示</h1>
        <p>这个应用会捕捉你的麦克风声音，实时分析其频谱。它会压低过强的频率，并用这部分能量补偿过弱的频率，试图让频谱变得“平坦”，同时保持每一小段音频的总音量不变。</p>
        <button id="toggleButton">Start Processing</button>
        <p class="warning">⚠️ 为避免啸叫，请务必使用耳机！</p>
        <canvas id="visualizer"></canvas>
    </div>

    <script>
        const toggleButton = document.getElementById('toggleButton');
        const canvas = document.getElementById('visualizer');
        const canvasCtx = canvas.getContext('2d');

        let audioContext;
        let sourceNode;
        let scriptProcessor;
        let analyserNode;
        let isProcessing = false;

        const FFT_SIZE = 2048; // FFT窗口大小，必须是2的幂
        const fft = new Fft(FFT_SIZE);
        
        // 用于可视化的数据
        let lastOriginalMagnitudes = new Float32Array(FFT_SIZE / 2);
        let lastModifiedMagnitudes = new Float32Array(FFT_SIZE / 2);
        let lastTargetLevel = 0;


        toggleButton.addEventListener('click', () => {
            if (!isProcessing) {
                startProcessing();
            } else {
                stopProcessing();
            }
        });

        async function startProcessing() {
            try {
                // 1. 创建音频上下文并获取麦克风流
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true, video: false });
                sourceNode = audioContext.createMediaStreamSource(stream);

                // 2. 创建 ScriptProcessorNode 用于实时处理
                // 参数: bufferSize, inputChannels, outputChannels
                scriptProcessor = audioContext.createScriptProcessor(FFT_SIZE, 1, 1);
                
                // 3. 创建 AnalyserNode 用于可视化（与处理并行，不影响输出）
                analyserNode = audioContext.createAnalyser();
                analyserNode.fftSize = FFT_SIZE;

                // 4. 设置音频处理回调函数
                scriptProcessor.onaudioprocess = processAudio;

                // 5. 连接音频图：Source -> Processor -> Destination
                //               Source -> Analyser (for visualization only)
                sourceNode.connect(scriptProcessor);
                scriptProcessor.connect(audioContext.destination);
                sourceNode.connect(analyserNode);

                isProcessing = true;
                toggleButton.textContent = 'Stop Processing';
                toggleButton.classList.add('active');
                
                drawVisualization();
                console.log("音频处理已开始...");

            } catch (err) {
                console.error('无法启动音频处理:', err);
                alert('错误：无法访问麦克风。请检查权限设置。\n' + err);
            }
        }

        function stopProcessing() {
            if (sourceNode) sourceNode.disconnect();
            if (scriptProcessor) scriptProcessor.disconnect();
            if (audioContext) audioContext.close();

            isProcessing = false;
            toggleButton.textContent = 'Start Processing';
            toggleButton.classList.remove('active');
            console.log("音频处理已停止。");
        }
        
        function processAudio(event) {
            const inputData = event.inputBuffer.getChannelData(0);
            const outputData = event.outputBuffer.getChannelData(0);

            // --- 步骤1: FFT ---
            const complexSpectrum = fft.createComplexArray();
            fft.realTransform(complexSpectrum, inputData);

            // --- 步骤2: 计算幅度和相位，并保存原始能量 ---
            const magnitudes = new Float32Array(FFT_SIZE / 2);
            const phases = new Float32Array(FFT_SIZE / 2);
            let originalPower = 0;

            for (let i = 0, j = 0; i < FFT_SIZE / 2; i++, j += 2) {
                const real = complexSpectrum[j];
                const imag = complexSpectrum[j + 1];
                magnitudes[i] = Math.sqrt(real * real + imag * imag);
                phases[i] = Math.atan2(imag, real);
                originalPower += magnitudes[i] * magnitudes[i];
            }
            
            // --- 步骤3: 执行“纠正”逻辑 ---
            const newMagnitudes = new Float32Array(magnitudes);

            // 计算目标电平（平均幅度）
            let sumMagnitudes = 0;
            for(let i = 0; i < newMagnitudes.length; i++) {
                sumMagnitudes += newMagnitudes[i];
            }
            const targetLevel = sumMagnitudes / newMagnitudes.length;
            
            // 找出超出部分和不足部分
            let excessPower = 0;
            const deficitIndices = [];
            let totalDeficit = 0;

            for (let i = 0; i < newMagnitudes.length; i++) {
                if (newMagnitudes[i] > targetLevel) {
                    excessPower += (newMagnitudes[i] * newMagnitudes[i]) - (targetLevel * targetLevel);
                    newMagnitudes[i] = targetLevel;
                } else {
                    deficitIndices.push(i);
                    totalDeficit += targetLevel - newMagnitudes[i];
                }
            }
            
            // 将多余能量按比例分配给不足的频率
            if (totalDeficit > 0) {
                 for (const i of deficitIndices) {
                    const deficit = targetLevel - newMagnitudes[i];
                    const powerToAdd = excessPower * (deficit / totalDeficit);
                    const newMagSq = (newMagnitudes[i] * newMagnitudes[i]) + powerToAdd;
                    newMagnitudes[i] = Math.sqrt(Math.max(0, newMagSq));
                }
            }
            
            // --- 步骤4: 可选的最终能量归一化 (确保能量守恒) ---
            let newPower = 0;
            for (let i = 0; i < newMagnitudes.length; i++) {
                newPower += newMagnitudes[i] * newMagnitudes[i];
            }
            if (newPower > 0) {
                const normFactor = Math.sqrt(originalPower / newPower);
                for (let i = 0; i < newMagnitudes.length; i++) {
                    newMagnitudes[i] *= normFactor;
                }
            }

            // 更新可视化数据
            lastOriginalMagnitudes.set(magnitudes);
            lastModifiedMagnitudes.set(newMagnitudes);
            lastTargetLevel = targetLevel;

            // --- 步骤5: 重建复数频谱并执行 IFFT ---
            const newComplexSpectrum = fft.createComplexArray();
            for (let i = 0, j = 0; i < FFT_SIZE / 2; i++, j += 2) {
                newComplexSpectrum[j] = newMagnitudes[i] * Math.cos(phases[i]);
                newComplexSpectrum[j + 1] = newMagnitudes[i] * Math.sin(phases[i]);
            }
            const timeDomainResult = fft.createComplexArray();
            fft.inverseTransform(timeDomainResult, newComplexSpectrum);
            
            // --- 步骤6: 填充输出缓冲区 ---
            for (let i = 0; i < FFT_SIZE; i++) {
                outputData[i] = timeDomainResult[i * 2]; // IFFT结果是复数，我们只需要实部
            }
        }

        function drawVisualization() {
            if (!isProcessing) {
                canvasCtx.fillStyle = '#282c34';
                canvasCtx.fillRect(0, 0, canvas.width, canvas.height);
                return;
            }

            requestAnimationFrame(drawVisualization);

            const bufferLength = analyserNode.frequencyBinCount;
            const dataArray = new Float32Array(bufferLength);
            analyserNode.getFloatFrequencyData(dataArray); // 获取原始频谱（dB）

            canvasCtx.fillStyle = '#282c34';
            canvasCtx.fillRect(0, 0, canvas.width, canvas.height);

            const barWidth = (canvas.width / bufferLength) * 1.5;
            let barHeight;
            let x = 0;

            // 绘制原始频谱 (蓝色)
            for (let i = 0; i < bufferLength; i++) {
                // 将dB转换为0-1的线性值
                const normalized = Math.pow(10, dataArray[i] / 20); 
                barHeight = normalized * canvas.height * 2;
                canvasCtx.fillStyle = 'rgba(0, 123, 255, 0.6)';
                canvasCtx.fillRect(x, canvas.height - barHeight, barWidth, barHeight);
                x += barWidth + 1;
            }
            
            // 绘制修改后的频谱 (红色)
            x = 0;
            // 找到修改后频谱的最大值用于归一化显示
            let maxModifiedMag = 0;
            for(let i=0; i<lastModifiedMagnitudes.length; i++) {
                if (lastModifiedMagnitudes[i] > maxModifiedMag) maxModifiedMag = lastModifiedMagnitudes[i];
            }

            if (maxModifiedMag > 0) {
                 for (let i = 0; i < lastModifiedMagnitudes.length; i++) {
                    const normalized = lastModifiedMagnitudes[i] / maxModifiedMag;
                    barHeight = normalized * canvas.height;
                    canvasCtx.fillStyle = 'rgba(220, 53, 69, 0.7)';
                    canvasCtx.fillRect(x, canvas.height - barHeight, barWidth, barHeight);
                    x += barWidth + 1;
                }

                // 绘制目标电平线 (绿色)
                const normalizedTarget = lastTargetLevel / maxModifiedMag;
                const targetY = canvas.height - (normalizedTarget * canvas.height);
                canvasCtx.beginPath();
                canvasCtx.moveTo(0, targetY);
                canvasCtx.lineTo(canvas.width, targetY);
                canvasCtx.strokeStyle = 'rgba(40, 167, 69, 0.8)';
                canvasCtx.lineWidth = 2;
                canvasCtx.setLineDash([5, 5]);
                canvasCtx.stroke();
                canvasCtx.setLineDash([]);
            }
        }
    </script>
</body>
</html>